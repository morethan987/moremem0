import os
from dotenv import load_dotenv
from mem0 import Memory
from format_results import format_search_results

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# è¯­è¨€æ¨¡å‹çš„API_KEYè¯·ç»Ÿä¸€å¡«å†™åœ¨.envæ–‡ä»¶ä¸­ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯»å–ï¼›
# ä¸è¦è¿›è¡Œé¢å¤–çš„æ‰‹åŠ¨è¾“å…¥ï¼Œå¯èƒ½ä¼šå¯¼è‡´API_KEYå†²çª
# ç³»ç»Ÿå†…éƒ¨çš„API_KEYä½¿ç”¨çš„æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å˜é‡ï¼Œå› æ­¤æ‰‹åŠ¨è¾“å…¥å¯èƒ½ä¼šå‘ç”Ÿå†²çª

# è¯­è¨€æ¨¡å‹
deepseek_config = {
    "provider": "deepseek",
    "config": {
        "model": "deepseek-chat",
        "temperature": 0.0, # æ¸©åº¦è®¾ä¸º0.0ï¼Œé˜²æ­¢AIä½œå¦–
        "top_p": 0.1, # è®¾ä¸º0.1ï¼Œé˜²æ­¢AIä½œå¦–
        "max_tokens": 8000,
        "deepseek_base_url": "https://api.deepseek.com/v1",  # Ensure this URL is correct
    },
}
aliyun_config = {
    "provider": "aliyun",
    "config": {
        "model": "qwen-max-latest",
        "temperature": 0.0, # æ¸©åº¦è®¾ä¸º0.0ï¼Œé˜²æ­¢AIä½œå¦–
        "top_p": 0.1, # è®¾ä¸º0.1ï¼Œé˜²æ­¢AIä½œå¦–
        "max_tokens": 8000,
        "aliyun_base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",  # Ensure this URL is correct
    },
}

# åµŒå…¥æ¨¡å‹
siliconflow_config = {
    "provider": "siliconflow",
    "config": {
        "model": "Pro/BAAI/bge-m3",
        "siliconflow_base_url": "https://api.siliconflow.cn/v1/embeddings",
        "api_key": os.getenv('SILICONFLOW_API_KEY'),
    },
}

# å‘é‡æ•°æ®åº“
qdrant_config = {
    "provider": "qdrant",
    "config": {
        "collection_name": "test",
        "host": "localhost",
        "port": 6333,
        "embedding_model_dims": 1024,  # Change this according to your local model's dimensions
    },
}

# å›¾æ•°æ®åº“
neo4j_config = {
    "provider": "neo4j",
    "config": {
        "url": "neo4j://localhost:7687",
        "username": "neo4j",
        "password": "mo123456789"
    },
    # "llm": deepseek_config,
}

# å®šåˆ¶åŒ–æç¤ºè¯ï¼Œä¼˜å…ˆçº§addçº§å±€éƒ¨æç¤ºè¯>ä¸»é…ç½®ä¸­çš„custom_prompt>ç³»ç»ŸåŸç”Ÿæç¤ºè¯:configs/prompts.py/FACT_RETRIEVAL_PROMPT
# å®šåˆ¶åŒ–å…¨å±€æç¤ºè¯
custom_prompt = """
Please only extract entities containing customer support information, order details, and user information. 
Here are some few shot examples:

Input: Hi.
Output: {{"facts" : []}}

Input: The weather is nice today.
Output: {{"facts" : []}}

Input: My order #12345 hasn't arrived yet.
Output: {{"facts" : ["Order #12345 not received"]}}

Input: I'm John Doe, and I'd like to return the shoes I bought last week.
Output: {{"facts" : ["Customer name: John Doe", "Wants to return shoes", "Purchase made last week"]}}

Input: I ordered a red shirt, size medium, but received a blue one instead.
Output: {{"facts" : ["Ordered red shirt, size medium", "Received blue shirt instead"]}}

Return the facts and customer information in a json format as shown above.
"""

# å®šåˆ¶åŒ–å±€éƒ¨æç¤ºè¯ï¼Œä½œç”¨åœ¨å‘é‡æ•°æ®åº“ä¸Š
add_prompt = """
è¿™æ˜¯ä¸€ä¸ªå±€éƒ¨æç¤ºè¯
"""

# å®šåˆ¶åŒ–å±€éƒ¨æç¤ºè¯ï¼Œä½œç”¨åœ¨å›¾æ•°æ®åº“ä¸Š
add_graph_prompt = """
è¿™æ˜¯ä¸€ä¸ªå±€éƒ¨æç¤ºè¯
"""

# ä¸»é…ç½®
config = {
    "vector_store": qdrant_config,
    "graph_store": neo4j_config,
    "llm": aliyun_config,
    "embedder": siliconflow_config,
    # "custom_prompt": custom_prompt,
    "version": "v1.1",
}

# Initialize Memory with the configuration
m = Memory.from_config(config)

initial_messages = [
    {"role": "user", "content": "ä½ å¥½ğŸ‘‹æˆ‘å«Morethanï¼Œæˆ‘å¾ˆå–œæ¬¢åƒé±¼"},
    {"role": "assistant", "content": "ä½ å¥½å‘€ï¼ŒMorethanï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚åƒé±¼æ˜¯ä¸ªå¾ˆæ£’çš„é€‰æ‹©å‘¢ï¼Œé±¼è‚‰ä¸ä»…é²œç¾ï¼Œè¿˜å¯Œå«ä¼˜è´¨è›‹ç™½è´¨ã€ä¸é¥±å’Œè„‚è‚ªé…¸ï¼Œå¯¹èº«ä½“æœ‰å¾ˆå¤šå¥½å¤„ã€‚ä½ æœ€å–œæ¬¢åƒä»€ä¹ˆé±¼ï¼Œæˆ–è€…ç”¨ä»€ä¹ˆæ–¹å¼çƒ¹é¥ªé±¼å‘¢ï¼Ÿ"}
]

test_messages = [
    {"role": "user", "content": "æˆ‘30åˆ†é’Ÿåè¦èƒŒ15ä¸ªå•è¯ï¼Œè®°å¾—æé†’æˆ‘"},
    {"role": "assistant", "content": "å¥½çš„ï¼Œ30åˆ†é’Ÿåæˆ‘ä¼šæé†’ä½ ã€‚"}
]

# è¾ƒå…¨çš„addå‘½ä»¤
# m.add(initial_messages, user_id="morethan", prompt=add_prompt, graph_prompt=add_graph_prompt, metadata={"food": "fish"})

# print(m.add(initial_messages, user_id="morethan", metadata={"food": "fish"}))
# m.add("I like pizza", user_id="morethan")

# print(m.add(test_messages, user_id="morethan"))

results = m.search("What will I do next?", user_id='morethan')

print(format_search_results(results))
