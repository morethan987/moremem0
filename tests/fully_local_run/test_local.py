import os
from dotenv import load_dotenv
from mem0 import Memory
from format_results import format_search_results
from datetime import datetime

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# è¯­è¨€æ¨¡å‹çš„API_KEYè¯·ç»Ÿä¸€å¡«å†™åœ¨.envæ–‡ä»¶ä¸­ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯»å–ï¼›
# ä¸è¦è¿›è¡Œé¢å¤–çš„æ‰‹åŠ¨è¾“å…¥ï¼Œå¯èƒ½ä¼šå¯¼è‡´API_KEYå†²çª
# ç³»ç»Ÿå†…éƒ¨çš„API_KEYä½¿ç”¨çš„æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å˜é‡ï¼Œå› æ­¤æ‰‹åŠ¨è¾“å…¥å¯èƒ½ä¼šå‘ç”Ÿå†²çª

# è¯­è¨€æ¨¡å‹
deepseek_config = {
    "provider": "deepseek",
    "config": {
        "model": "deepseek-chat",
        "temperature": 0.0, # æ¸©åº¦è®¾ä¸º0.0ï¼Œé˜²æ­¢AIä½œå¦–
        "top_p": 0.1, # è®¾ä¸º0.1ï¼Œé˜²æ­¢AIä½œå¦–
        "max_tokens": 8000,
        "deepseek_base_url": "https://api.deepseek.com/v1",  # Ensure this URL is correct
    },
}
aliyun_config = {
    "provider": "aliyun",
    "config": {
        "model": "qwen-max-latest",
        "temperature": 0.0, # æ¸©åº¦è®¾ä¸º0.0ï¼Œé˜²æ­¢AIä½œå¦–
        "top_p": 0.1, # è®¾ä¸º0.1ï¼Œé˜²æ­¢AIä½œå¦–
        "max_tokens": 8000,
        "aliyun_base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",  # Ensure this URL is correct
    },
}

# åµŒå…¥æ¨¡å‹
siliconflow_config = {
    "provider": "siliconflow",
    "config": {
        "model": "Pro/BAAI/bge-m3",
        "siliconflow_base_url": "https://api.siliconflow.cn/v1/embeddings",
        "api_key": os.getenv('SILICONFLOW_API_KEY'),
    },
}

custom_categories = [
    {"personal_information": "Basic information about the user including name, preferences, and personality traits"},
    {"health": "Physical and mental health status, medical history, and wellness routines"}
]

# å‘é‡æ•°æ®åº“
qdrant_config = {
    "provider": "qdrant",
    "config": {
        "collection_name": "test",
        "host": "localhost",
        "port": 6333,
        "embedding_model_dims": 1024,  # Change this according to your local model's dimensions
    },
    # é’ˆå¯¹å‘é‡æ•°æ®åº“çš„è‡ªå®šä¹‰æç¤ºè¯
    # "custom_prompt": custom_prompt_for_vector,
    "custom_categories": custom_categories,
}

# ä¹Ÿå¯ä»¥åœ¨graph_storeçš„é…ç½®ä¸­ç›´æ¥è®¾ç½®ï¼Œé¿å…addæŒ‡ä»¤è¿‡äºå¤æ‚
custom_node_types = [
    {"food_preference": "User's preference for food"},
    {"pet": "stands for the all kinds of pets"},
    {"health_condition": "Physical and mental health status, medical history, and wellness routines"},
    {"person": "The person mentioned by user. The user himself also belong to this type"}
]

# ä¹Ÿå¯ä»¥åœ¨graph_storeçš„é…ç½®ä¸­ç›´æ¥è®¾ç½®ï¼Œé¿å…addæŒ‡ä»¤è¿‡äºå¤æ‚
custom_relations = [
    {"likes_to_eat": "Express user's preference for food"},
    {"has_a_pet": "Express the user has a pet"},
    {"with_health_condition": "Express user has a specific health condition"}
]

# å›¾æ•°æ®åº“
neo4j_config = {
    "provider": "neo4j",
    "config": {
        "url": "neo4j://localhost:7687",
        "username": "neo4j",
        "password": "mo123456789"
    },
    # "llm": deepseek_config,
    # é’ˆå¯¹å›¾æ•°æ®åº“çš„è‡ªå®šä¹‰æç¤ºè¯
    # "custom_prompt": custom_prompt_for_graph,
    "custom_node_types": custom_node_types,
    "custom_relations": custom_relations,
}

# ä¸»é…ç½®
config = {
    "vector_store": qdrant_config,
    "graph_store": neo4j_config,
    "llm": aliyun_config,
    "embedder": siliconflow_config,
    "version": "v1.1",
}

# Initialize Memory with the configuration
m = Memory.from_config(config)

initial_messages = [
    {"role": "user", "content": "ä½ å¥½ğŸ‘‹æˆ‘å«Morethanï¼Œæˆ‘å¾ˆå–œæ¬¢åƒé±¼"},
    {"role": "assistant", "content": "ä½ å¥½å‘€ï¼ŒMorethanï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚åƒé±¼æ˜¯ä¸ªå¾ˆæ£’çš„é€‰æ‹©å‘¢ï¼Œé±¼è‚‰ä¸ä»…é²œç¾ï¼Œè¿˜å¯Œå«ä¼˜è´¨è›‹ç™½è´¨ã€ä¸é¥±å’Œè„‚è‚ªé…¸ï¼Œå¯¹èº«ä½“æœ‰å¾ˆå¤šå¥½å¤„ã€‚ä½ æœ€å–œæ¬¢åƒä»€ä¹ˆé±¼ï¼Œæˆ–è€…ç”¨ä»€ä¹ˆæ–¹å¼çƒ¹é¥ªé±¼å‘¢ï¼Ÿ"},
    {"role": "user", "content": "æˆ‘å–œæ¬¢åƒæŠ«è¨ï¼Œæˆ‘ä»Šå¹´12å²ï¼Œæˆ‘ç»å¸¸æ„Ÿå†’"}
]

excluded_info = {
    "vector": "1. ç”¨æˆ·å¯¹äºé£Ÿç‰©çš„åå¥½",
    "graph": "1. ç”¨æˆ·å¯¹äºé£Ÿç‰©çš„åå¥½\n2. ç”¨æˆ·çš„å¹´é¾„"
}

test_messages = [
    {"role": "user", "content": "I like to eat pizza, I have a dog named Pitter."}
]

# è¾ƒå…¨çš„addå‘½ä»¤
# m.add(initial_messages, user_id="morethan", prompt=add_prompt, graph_prompt=add_graph_prompt, metadata={"food": "fish"}, , includes=included_info, excludes=excluded_info, custom_categories=custom_categories, custom_node_types=custom_node_types, custom_relations=custom_relations)

print(m.add(test_messages, user_id="morethan"))
# m.add("I like pizza", user_id="morethan")

# print(m.add(test_messages, user_id="morethan", custom_categories=custom_categories))

# results = m.search("What do you know about me?", user_id='morethan')
# print(format_search_results(results))
